{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96a49311",
   "metadata": {},
   "source": [
    "# Traditional ML\n",
    "\n",
    "Using the csv files we generated from the \"02 VoiceSentiment-Feature_Extraction\", we will build models using the “traditional” machine learning  to be used as baseline when we build our deep learning model. \n",
    "\n",
    "1. Load our train and test dataset\n",
    "2. Base Model\n",
    "3. Define X and Y\n",
    "4. Need to scale the data before we build our models\n",
    "5. Building Models\n",
    "    - 5.1 MLP\n",
    "    - 5.2 RandomForest\n",
    "    - 5.3 Logistic Regression\n",
    "    - 5.4 VotingClassifier\n",
    "6. Metrics\n",
    "7. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d70b0b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#boosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier, VotingClassifier\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,StratifiedKFold, cross_val_score\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb127e0b",
   "metadata": {},
   "source": [
    "### 1. Load our train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80320fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data\n",
    "df_train = pd.read_csv(\"./dataset/train.csv\")\n",
    "df_test = pd.read_csv(\"./dataset/test.csv\")\n",
    "\n",
    "#remove the index column\n",
    "df_train = df_train.drop(columns='Unnamed: 0')\n",
    "df_test = df_test.drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "277ab88f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10188, 186)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99402ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1132, 186)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cca7819",
   "metadata": {},
   "source": [
    "## 2. Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb022982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "disgust      0.143993\n",
       "fear         0.143993\n",
       "happy        0.143993\n",
       "sad          0.143993\n",
       "angry        0.143993\n",
       "surprised    0.143993\n",
       "neutral      0.136042\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[\"label\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53559e43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fear         0.143993\n",
       "happy        0.143993\n",
       "surprised    0.143993\n",
       "sad          0.143993\n",
       "angry        0.143993\n",
       "disgust      0.143993\n",
       "neutral      0.136042\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"label\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559af292",
   "metadata": {},
   "source": [
    "## Base Model is around 14%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4176699",
   "metadata": {},
   "source": [
    "### 3. Define X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7c3edd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting categorical labels to numeric for test dataset\n",
    "factor_test = pd.factorize(df_test['label'], sort=True)\n",
    "df_test['label'] = factor_test[0]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b35702d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting categorical labels to numeric for train dataset\n",
    "factor_train= pd.factorize(df_train['label'], sort=True)\n",
    "df_train['label'] = factor_train[0]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a692b14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#since we already split our data to train and test in the prior notebook, we will just assign the values accordingly\n",
    "X_train = df_train.drop(columns=[\"label\", \"file\"])\n",
    "y_train = df_train[\"label\"]\n",
    "\n",
    "X_test = df_test.drop(columns=[\"label\", \"file\"])\n",
    "y_test = df_test[\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d668aec",
   "metadata": {},
   "source": [
    "### 4. Need to scale the data before we build our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aaad8d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling our data with sklearn's Standard scaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d368e99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(name, model):\n",
    "    \n",
    "    models[name] = {}\n",
    "    \n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(f\"Model Fitting.. {name} Current Time = {current_time}\")\n",
    "        \n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    \n",
    "    models[name][\"train_score\"] = model.score(X_train, y_train)\n",
    "    models[name][\"test_score\"] = model.score(X_test, y_test)\n",
    "    models[name][\"model\"] = model\n",
    "\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize = (10, 5))\n",
    "    cm = pd.DataFrame(cm , index = [i for i in factor_test[1]] , columns = [i for i in factor_test[1]])\n",
    "    sns.heatmap(cm, linecolor='white', cmap='Blues', linewidth=1, annot=True, fmt='')\n",
    "\n",
    "    plt.title('Confusion Matrix', size=20)\n",
    "    plt.xlabel('Predicted Labels', size=14)\n",
    "    plt.ylabel('Actual Labels', size=14)\n",
    "    plt.show()\n",
    "\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(f\"Model Completion.. {name} Current Time = {current_time}\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cdb2a3",
   "metadata": {},
   "source": [
    "### 5. Building Models\n",
    "\n",
    "***BEST PARAMETERS obtained by using OPTUNA***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0589635",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e88e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Fitting.. mlp Current Time = 19:16:59\n"
     ]
    }
   ],
   "source": [
    "## 5.1 Multi-layer Perceptron classifier.\n",
    "\n",
    "mlp = MLPClassifier(activation= 'relu', \n",
    "              solver= 'sgd', \n",
    "              hidden_layer_sizes= 1200, \n",
    "              alpha= 0.255, \n",
    "              batch_size= 200, \n",
    "              learning_rate= 'constant',\n",
    "              max_iter=10000)\n",
    "build_model('mlp', mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdc0243",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5.2 Random Forest\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators= 650\n",
    "                            , max_depth= 85\n",
    "                            , criterion= 'entropy')\n",
    "rf = build_model('rf', rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706bf1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5.3 Logistic Regression\n",
    "\n",
    "lr = LogisticRegression(multi_class = 'multinomial'\n",
    "                        , penalty = 'l2'\n",
    "                        ,solver = 'saga'\n",
    "                        , max_iter= 10000)\n",
    "\n",
    "lr = build_model(\"lr\", lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc88e847",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5.4 Voting Classifier\n",
    "\n",
    "vote = VotingClassifier([\n",
    "    ('mlp', MLPClassifier(activation= 'relu', \n",
    "              solver= 'sgd', \n",
    "              hidden_layer_sizes= 1200, \n",
    "              alpha= 0.255, \n",
    "              batch_size= 200, \n",
    "              learning_rate= 'constant',\n",
    "              max_iter=10000)),\n",
    "    ('rf', RandomForestClassifier(max_depth = 85\n",
    "                                  ,n_estimators = 650\n",
    "                                  ,random_state= 0))\n",
    "    ], voting=\"soft\")\n",
    "\n",
    "vote = build_model(\"vc\", vote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecb3304",
   "metadata": {},
   "outputs": [],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97de0615",
   "metadata": {},
   "source": [
    "### 6. Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45841fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_list = []\n",
    "\n",
    "for model in models:\n",
    "        dic = {\"model\": model,\n",
    "                \"test_score\": models[model][\"test_score\"]\n",
    "        }\n",
    "        score_list.append(dic)\n",
    "df_score = pd.DataFrame(score_list)\n",
    "df_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185bc1b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "509f5f71",
   "metadata": {},
   "source": [
    "### Save the best model for future prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bbbb0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5dd52794",
   "metadata": {},
   "source": [
    "## 7. SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43314f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c93c83e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af8afaa6",
   "metadata": {},
   "source": [
    "## OPTUNA.\n",
    "#### This ran for a long time and used to search for the best params using Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a27f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_mlp(trial):\n",
    "\n",
    "    params = {\n",
    "        'activation': trial.suggest_categorical('activation', ['logistic', 'tanh', 'relu']),\n",
    "        'solver': trial.suggest_categorical('solver', ['lbfgs', 'sgd', 'adam']),\n",
    "        'hidden_layer_sizes':trial.suggest_int('hidden_layer_sizes', 100, 1500),\n",
    "        'alpha': trial.suggest_uniform('alpha', 0.001, 0.99),\n",
    "        'batch_size':trial.suggest_int('batch_size', 150, 300), \n",
    "        'learning_rate': trial.suggest_categorical('learning_rate', ['adaptive', 'constant', 'invscaling']),\n",
    "        'max_iter': 10000\n",
    "        }\n",
    "  \n",
    "    model = MLPClassifier(**params, random_state = 22) \n",
    "    \n",
    "    model.set_params(**params)\n",
    "\n",
    "    return np.mean(cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b25da59",
   "metadata": {},
   "outputs": [],
   "source": [
    "## MLP\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective_mlp, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2796f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_rf(trial):\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=5, random_state=0, shuffle=True)\n",
    "        \n",
    "    params = {\n",
    "         'n_estimators': trial.suggest_categorical('n_estimators', [650, 700]),\n",
    "         'max_depth': trial.suggest_categorical('max_depth', [80, 85]),\n",
    "         'criterion': trial.suggest_categorical('criterion', ['entropy'])\n",
    "        }\n",
    "  \n",
    "    model = RandomForestClassifier(**params, random_state = 0) \n",
    "    \n",
    "    model.set_params(**params)\n",
    "\n",
    "    return np.mean(cross_val_score(model, X_train_scaled, y_train, cv=kfold, scoring='accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f426d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## RANDOM FOREST\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective_rf, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e281e123",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_lr(trial):\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=5, random_state=0, shuffle=True)\n",
    "        \n",
    "    params = {\n",
    "         'multi_class': trial.suggest_categorical('multi_class', ['multinomial']),\n",
    "         'penalty': trial.suggest_categorical('penalty', ['l1', 'l2']),\n",
    "         'solver': trial.suggest_categorical('solver', ['saga']),\n",
    "         'max_iter': 10000\n",
    "        }\n",
    "  \n",
    "    model = LogisticRegression(**params, random_state = 0) \n",
    "    \n",
    "    model.set_params(**params)\n",
    "\n",
    "    return np.mean(cross_val_score(model, X_train_scaled, y_train, cv=kfold, scoring='accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de961a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Logistic Regression\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective_lr, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af058f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
